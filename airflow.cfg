[core]
dags_folder = C:/Users/allan/airflow/dags
executor = LocalExecutor
base_log_folder = C:/Users/allan/airflow/logs
sql_alchemy_conn = postgresql+psycopg2://seu_usuario:admin2@localhost/airflow


# Chave Fernet para criptografia de senhas e conexões (substitua pela sua)
fernet_key = gkmUpkpXYWSHjMgKsRnhkvlXIx5jTMRw_UvMYPm8swg=

# Número máximo de processos simultâneos
parallelism = 32

# Caminho para arquivos temporários
tmp_dir = C:/Users/allan/airflow/tmp

[logging]
# Nível de log do Airflow
logging_level = INFO

# Diretório de logs do webserver
base_log_folder = C:/Users/allan/airflow/logs

# Caminho dos logs do scheduler
scheduler_log_file = C:/Users/allan/airflow/logs/scheduler/scheduler.log

# Tamanho do pool de conexões ao banco de dados para logs
sql_alchemy_pool_size = 5

[webserver]
# Porta do Airflow Webserver
web_server_port = 8080

# Endereço do host para o Airflow Webserver
web_server_host = 0.0.0.0

# Caminho do arquivo de logs do Webserver
web_server_log_file = C:/Users/allan/airflow/logs/webserver.log

[scheduler]
# Número máximo de threads para processamento das DAGs
max_threads = 2

# Intervalo de verificação das DAGs em segundos
dag_dir_list_interval = 60

# Intervalo de heartbeat do scheduler em segundos
scheduler_heartbeat_sec = 5

# Diretório para arquivos temporários do scheduler
child_process_log_directory = C:/Users/allan/airflow/logs/scheduler

[database]
# Tamanho do pool de conexões do banco de dados
sql_alchemy_pool_size = 5

# Número de segundos antes de um pool de conexões expirar
sql_alchemy_pool_recycle = 1800

[celery]
# Se você optar por usar o CeleryExecutor, ajuste essas configurações:
broker_url = redis://localhost:6379/0
result_backend = db+postgresql://airflow:password@localhost:5432/airflow

[cli]
# Adiciona a configuração de execução para o CLI do Airflow
cli_auto_envvar_prefix = AIRFLOW

[api]
# Configurações da API REST do Airflow
auth_backend = airflow.api.auth.backend.basic_auth

[operators]
# Proprietário padrão das tarefas
default_owner = airflow
